#Configurations
env: development
data:
  batch_size: 256
  image_size: 224
  image_depth: 3
  dataset_folder: "./dog_breed_classification/downstream/"
  num_workers: 8
  shuffle: true
  use_random_horizontal_flip: true
  random_affine:
    degrees: 
      - 20
      - 50
    translate: 
      - 0.1
      - 0.3
    scale:
      - 0.4
      - 0.6
  color_jitter:
    brightness: 0.5
    hue: 0.3
model:
  patch_size: 14 #in the train conf file, this param was in the 'mask' section.
  trained_encoder_predictor_saved_folder: ./artifacts/train/
  model_save_folder: ./artifacts/downstream/
  N_saved_model_to_keep: 20 #keep the last N number of saved models and delete the earlier ones.
  model_save_freq: 2 #save every N epoch.
  trained_encoder_predictor_model_name: i-jepa-dog-breed
  model_name: i-jepa-dog-breed-classification
  transformer_depth: 10
  encoder_network_embedding_dim: 512 #embedding dimension to be used throughout the transformer blocks in the encoder network.
  predictor_network_embedding_dim: 512 #embedding dimension to be used throughout the transformer blocks in the predictor network.
  classification_embedding_dim: 1024
  projection_keys_dim : 256
  projection_values_dim : 256
  num_class: 77
  feedforward_projection_dim : 1024 
  num_heads : 8
  attn_dropout_prob : 0.1
  feedforward_dropout_prob : 0.1

training:
  device : gpu
  load_checkpoint: true
  load_checkpoint_epoch: null
  start_epoch : 0
  end_epoch : 30
  learning_rate : 1.0e-3
  use_bfloat16: true
  use_neptune: true




