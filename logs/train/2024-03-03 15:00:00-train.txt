03-03-2024 15:00:06:[INFO]:__main__:train:174 - Init Encoder model... - [0:00:04.510328]
03-03-2024 15:00:07:[INFO]:__main__:train:190 - Init Predictor model... - [0:00:05.220528]
03-03-2024 15:00:07:[INFO]:__main__:train:209 - Init MultiBlockMaskCollator module... - [0:00:05.275450]
03-03-2024 15:00:07:[INFO]:__main__:train:235 - Init local dataset loading module... - [0:00:05.277058]
03-03-2024 15:00:08:[INFO]:__main__:train:245 - Dataloader is loaded! Total iteration per epoch: 24153 - [0:00:06.377190]
03-03-2024 15:00:09:[INFO]:utils:load_checkpoint:172 - Checkpoint from epoch {epoch} is successfully loaded! Extracting the parameters to load to individual model/variabels now... - [0:00:06.964903]
03-03-2024 15:00:09:[ERROR]:utils:load_checkpoint:193 - Error loading the model! Error(s) in loading state_dict for VisionTransformerForEncoder:
	Missing key(s) in state_dict: "transformer_blocks.10.multi_head_attention_block.0.weight", "transformer_blocks.10.multi_head_attention_block.0.bias", "transformer_blocks.10.multi_head_attention_block.1.Wq_Wk.weight", "transformer_blocks.10.multi_head_attention_block.1.Wq_Wk.bias", "transformer_blocks.10.multi_head_attention_block.1.Wv.weight", "transformer_blocks.10.multi_head_attention_block.1.Wv.bias", "transformer_blocks.10.multi_head_attention_block.1.W_o.weight", "transformer_blocks.10.multi_head_attention_block.1.W_o.bias", "transformer_blocks.10.feedforward_block.0.weight", "transformer_blocks.10.feedforward_block.0.bias", "transformer_blocks.10.feedforward_block.1.0.weight", "transformer_blocks.10.feedforward_block.1.0.bias", "transformer_blocks.10.feedforward_block.1.3.weight", "transformer_blocks.10.feedforward_block.1.3.bias", "transformer_blocks.11.multi_head_attention_block.0.weight", "transformer_blocks.11.multi_head_attention_block.0.bias", "transformer_blocks.11.multi_head_attention_block.1.Wq_Wk.weight", "transformer_blocks.11.multi_head_attention_block.1.Wq_Wk.bias", "transformer_blocks.11.multi_head_attention_block.1.Wv.weight", "transformer_blocks.11.multi_head_attention_block.1.Wv.bias", "transformer_blocks.11.multi_head_attention_block.1.W_o.weight", "transformer_blocks.11.multi_head_attention_block.1.W_o.bias", "transformer_blocks.11.feedforward_block.0.weight", "transformer_blocks.11.feedforward_block.0.bias", "transformer_blocks.11.feedforward_block.1.0.weight", "transformer_blocks.11.feedforward_block.1.0.bias", "transformer_blocks.11.feedforward_block.1.3.weight", "transformer_blocks.11.feedforward_block.1.3.bias", "transformer_blocks.12.multi_head_attention_block.0.weight", "transformer_blocks.12.multi_head_attention_block.0.bias", "transformer_blocks.12.multi_head_attention_block.1.Wq_Wk.weight", "transformer_blocks.12.multi_head_attention_block.1.Wq_Wk.bias", "transformer_blocks.12.multi_head_attention_block.1.Wv.weight", "transformer_blocks.12.multi_head_attention_block.1.Wv.bias", "transformer_blocks.12.multi_head_attention_block.1.W_o.weight", "transformer_blocks.12.multi_head_attention_block.1.W_o.bias", "transformer_blocks.12.feedforward_block.0.weight", "transformer_blocks.12.feedforward_block.0.bias", "transformer_blocks.12.feedforward_block.1.0.weight", "transformer_blocks.12.feedforward_block.1.0.bias", "transformer_blocks.12.feedforward_block.1.3.weight", "transformer_blocks.12.feedforward_block.1.3.bias", "transformer_blocks.13.multi_head_attention_block.0.weight", "transformer_blocks.13.multi_head_attention_block.0.bias", "transformer_blocks.13.multi_head_attention_block.1.Wq_Wk.weight", "transformer_blocks.13.multi_head_attention_block.1.Wq_Wk.bias", "transformer_blocks.13.multi_head_attention_block.1.Wv.weight", "transformer_blocks.13.multi_head_attention_block.1.Wv.bias", "transformer_blocks.13.multi_head_attention_block.1.W_o.weight", "transformer_blocks.13.multi_head_attention_block.1.W_o.bias", "transformer_blocks.13.feedforward_block.0.weight", "transformer_blocks.13.feedforward_block.0.bias", "transformer_blocks.13.feedforward_block.1.0.weight", "transformer_blocks.13.feedforward_block.1.0.bias", "transformer_blocks.13.feedforward_block.1.3.weight", "transformer_blocks.13.feedforward_block.1.3.bias", "transformer_blocks.14.multi_head_attention_block.0.weight", "transformer_blocks.14.multi_head_attention_block.0.bias", "transformer_blocks.14.multi_head_attention_block.1.Wq_Wk.weight", "transformer_blocks.14.multi_head_attention_block.1.Wq_Wk.bias", "transformer_blocks.14.multi_head_attention_block.1.Wv.weight", "transformer_blocks.14.multi_head_attention_block.1.Wv.bias", "transformer_blocks.14.multi_head_attention_block.1.W_o.weight", "transformer_blocks.14.multi_head_attention_block.1.W_o.bias", "transformer_blocks.14.feedforward_block.0.weight", "transformer_blocks.14.feedforward_block.0.bias", "transformer_blocks.14.feedforward_block.1.0.weight", "transformer_blocks.14.feedforward_block.1.0.bias", "transformer_blocks.14.feedforward_block.1.3.weight", "transformer_blocks.14.feedforward_block.1.3.bias", "transformer_blocks.15.multi_head_attention_block.0.weight", "transformer_blocks.15.multi_head_attention_block.0.bias", "transformer_blocks.15.multi_head_attention_block.1.Wq_Wk.weight", "transformer_blocks.15.multi_head_attention_block.1.Wq_Wk.bias", "transformer_blocks.15.multi_head_attention_block.1.Wv.weight", "transformer_blocks.15.multi_head_attention_block.1.Wv.bias", "transformer_blocks.15.multi_head_attention_block.1.W_o.weight", "transformer_blocks.15.multi_head_attention_block.1.W_o.bias", "transformer_blocks.15.feedforward_block.0.weight", "transformer_blocks.15.feedforward_block.0.bias", "transformer_blocks.15.feedforward_block.1.0.weight", "transformer_blocks.15.feedforward_block.1.0.bias", "transformer_blocks.15.feedforward_block.1.3.weight", "transformer_blocks.15.feedforward_block.1.3.bias". 
	size mismatch for patch_embed.patch_projection.weight: copying a param with shape torch.Size([512, 3, 14, 14]) from checkpoint, the shape in current model is torch.Size([1024, 3, 14, 14]).
	size mismatch for patch_embed.patch_projection.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.0.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.0.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.0.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.0.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.0.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.0.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.0.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.0.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.0.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.0.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.0.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.0.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.0.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.0.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.1.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.1.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.1.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.1.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.1.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.1.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.1.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.1.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.1.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.1.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.1.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.1.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.1.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.1.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.2.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.2.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.2.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.2.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.2.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.2.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.2.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.2.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.2.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.2.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.2.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.2.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.2.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.2.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.3.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.3.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.3.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.3.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.3.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.3.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.3.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.3.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.3.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.3.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.3.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.3.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.3.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.3.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.4.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.4.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.4.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.4.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.4.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.4.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.4.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.4.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.4.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.4.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.4.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.4.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.4.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.4.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.5.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.5.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.5.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.5.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.5.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.5.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.5.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.5.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.5.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.5.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.5.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.5.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.5.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.5.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.6.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.6.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.6.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.6.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.6.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.6.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.6.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.6.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.6.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.6.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.6.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.6.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.6.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.6.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.7.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.7.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.7.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.7.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.7.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.7.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.7.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.7.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.7.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.7.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.7.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.7.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.7.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.7.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.8.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.8.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.8.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.8.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.8.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.8.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.8.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.8.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.8.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.8.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.8.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.8.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.8.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.8.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.9.multi_head_attention_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.9.multi_head_attention_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.9.multi_head_attention_block.1.Wq_Wk.weight: copying a param with shape torch.Size([512, 512]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).
	size mismatch for transformer_blocks.9.multi_head_attention_block.1.Wq_Wk.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).
	size mismatch for transformer_blocks.9.multi_head_attention_block.1.Wv.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.9.multi_head_attention_block.1.Wv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.9.multi_head_attention_block.1.W_o.weight: copying a param with shape torch.Size([512, 256]) from checkpoint, the shape in current model is torch.Size([1024, 1024]).
	size mismatch for transformer_blocks.9.multi_head_attention_block.1.W_o.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.9.feedforward_block.0.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.9.feedforward_block.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for transformer_blocks.9.feedforward_block.1.0.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).
	size mismatch for transformer_blocks.9.feedforward_block.1.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([4096]).
	size mismatch for transformer_blocks.9.feedforward_block.1.3.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).
	size mismatch for transformer_blocks.9.feedforward_block.1.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for final_layernorm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for final_layernorm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]). - [0:00:06.966162]
03-03-2024 15:00:09:[INFO]:__main__:train:285 - Total data to train the SSL model: 386444 - [0:00:06.967900]
03-03-2024 15:00:09:[INFO]:__main__:train:288 - Training has started for epoch 0 - [0:00:06.968088]
